{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanta\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (0,1,2,4,5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "C:\\Users\\yanta\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (0,1,2,5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7c70b341f380>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mdataset3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moff_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mfeature3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moff_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;34m'20160315'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;34m'20160630'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'null'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;34m'20160315'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;34m'20160630'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[0mdataset2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moff_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;34m'20160515'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;34m'20160615'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mfeature2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moff_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;34m'20160201'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;34m'20160514'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m|\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'null'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;34m'20160201'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moff_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_received\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;34m'20160514'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomparison_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomp_method_OBJECT_ARRAY\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py\u001b[0m in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\ops.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "dataset split:\n",
    "                      (date_received)                              \n",
    "           dateset3: 20160701~20160731 (113640),features3 from 20160315~20160630  (off_test)\n",
    "           dateset2: 20160515~20160615 (258446),features2 from 20160201~20160514  \n",
    "           dateset1: 20160414~20160514 (138303),features1 from 20160101~20160413        \n",
    "1.merchant related: \n",
    "      sales_use_coupon. total_coupon\n",
    "      transfer_rate = sales_use_coupon/total_coupon.\n",
    "      merchant_avg_distance,merchant_min_distance,merchant_max_distance of those use coupon \n",
    "      total_sales.  coupon_rate = sales_use_coupon/total_sales.  \n",
    "       \n",
    "2.coupon related: \n",
    "      discount_rate. discount_man. discount_jian. is_man_jian\n",
    "      day_of_week,day_of_month. (date_received)\n",
    "      \n",
    "3.user related: \n",
    "      distance. \n",
    "      user_avg_distance, user_min_distance,user_max_distance. \n",
    "      buy_use_coupon. buy_total. coupon_received.\n",
    "      buy_use_coupon/coupon_received. \n",
    "      avg_diff_date_datereceived. min_diff_date_datereceived. max_diff_date_datereceived.  \n",
    "      count_merchant.  \n",
    "4.user_merchant:\n",
    "      times_user_buy_merchant_before.\n",
    "     \n",
    "5. other feature:\n",
    "      this_month_user_receive_all_coupon_count\n",
    "      this_month_user_receive_same_coupon_count\n",
    "      this_month_user_receive_same_coupon_lastone\n",
    "      this_month_user_receive_same_coupon_firstone\n",
    "      this_day_user_receive_all_coupon_count\n",
    "      this_day_user_receive_same_coupon_count\n",
    "      day_gap_before, day_gap_after  (receive the same coupon)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#1754884 record,1053282 with coupon_id,9738 coupon. date_received:20160101~20160615,date:20160101~20160630, 539438 users, 8415 merchants\n",
    "off_train = pd.read_csv('C:/Users/yanta/Desktop/MSBD 5012 ML/project/ccf_offline_stage1_train/ccf_offline_stage1_train.csv',header=None,low_memory=False)\n",
    "off_train.columns = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']\n",
    "#2050 coupon_id. date_received:20160701~20160731, 76309 users(76307 in trainset, 35965 in online_trainset), 1559 merchants(1558 in trainset)\n",
    "off_test = pd.read_csv('ccf_offline_stage1_test_revised.csv',header=None,low_memory=False)\n",
    "off_test.columns = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received']\n",
    "#11429826 record(872357 with coupon_id),762858 user(267448 in off_train)\n",
    "on_train = pd.read_csv('C:/Users/yanta/Desktop/MSBD 5012 ML/project/ccf_online_stage2_train/ccf_online_stage1_train.csv',header=None,low_memory=False)\n",
    "on_train.columns = ['user_id','merchant_id','action','coupon_id','discount_rate','date_received','date']\n",
    "\n",
    "\n",
    "dataset3 = off_test\n",
    "feature3 = off_train[((off_train.date>='20160315')&(off_train.date<='20160630'))|((off_train.date=='null')&(off_train.date_received>='20160315')&(off_train.date_received<='20160630'))]\n",
    "dataset2 = off_train[(off_train.date_received>='20160515')&(off_train.date_received<='20160615')]\n",
    "feature2 = off_train[(off_train.date>='20160201')&(off_train.date<='20160514')|((off_train.date=='null')&(off_train.date_received>='20160201')&(off_train.date_received<='20160514'))]\n",
    "dataset1 = off_train[(off_train.date_received>='20160414')&(off_train.date_received<='20160514')]\n",
    "feature1 = off_train[(off_train.date>='20160101')&(off_train.date<='20160413')|((off_train.date=='null')&(off_train.date_received>='20160101')&(off_train.date_received<='20160413'))]\n",
    "\n",
    "\n",
    "############# other feature ##################3\n",
    "\n",
    "##################  user_merchant related feature #########################\n",
    "\n",
    "\"\"\"\n",
    "4.user_merchant:\n",
    "      times_user_buy_merchant_before. \n",
    "\"\"\"\n",
    "#for dataset3\n",
    "all_user_merchant = feature3[['user_id','merchant_id']].copy()\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "t = feature3[['user_id','merchant_id','date']]\n",
    "t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = feature3[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace=True)\n",
    "\n",
    "t2 = feature3[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace=True)\n",
    "\n",
    "t3 = feature3[['user_id','merchant_id']].copy()\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace=True)\n",
    "\n",
    "t4 = feature3[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "user_merchant3 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3 = pd.merge(user_merchant3,t4,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant3.user_merchant_buy_use_coupon = user_merchant3.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant3.user_merchant_buy_common = user_merchant3.user_merchant_buy_common.replace(np.nan,0)\n",
    "user_merchant3['user_merchant_coupon_transfer_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_received.astype('float')\n",
    "user_merchant3['user_merchant_coupon_buy_rate'] = user_merchant3.user_merchant_buy_use_coupon.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "user_merchant3['user_merchant_rate'] = user_merchant3.user_merchant_buy_total.astype('float') / user_merchant3.user_merchant_any.astype('float')\n",
    "user_merchant3['user_merchant_common_buy_rate'] = user_merchant3.user_merchant_buy_common.astype('float') / user_merchant3.user_merchant_buy_total.astype('float')\n",
    "user_merchant3.to_csv('C:/Users/yanta/Desktop/MSBD 5012 ML/project/user_merchant3.csv',index=None)\n",
    "\n",
    "#for dataset2\n",
    "all_user_merchant = feature2[['user_id','merchant_id']].copy()\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "t = feature2[['user_id','merchant_id','date']]\n",
    "t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = feature2[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace=True)\n",
    "\n",
    "t2 = feature2[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace=True)\n",
    "\n",
    "t3 = feature2[['user_id','merchant_id']].copy()\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace=True)\n",
    "\n",
    "t4 = feature2[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "user_merchant2 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2 = pd.merge(user_merchant2,t4,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant2.user_merchant_buy_use_coupon = user_merchant2.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant2.user_merchant_buy_common = user_merchant2.user_merchant_buy_common.replace(np.nan,0)\n",
    "user_merchant2['user_merchant_coupon_transfer_rate'] = user_merchant2.user_merchant_buy_use_coupon.astype('float') / user_merchant2.user_merchant_received.astype('float')\n",
    "user_merchant2['user_merchant_coupon_buy_rate'] = user_merchant2.user_merchant_buy_use_coupon.astype('float') / user_merchant2.user_merchant_buy_total.astype('float')\n",
    "user_merchant2['user_merchant_rate'] = user_merchant2.user_merchant_buy_total.astype('float') / user_merchant2.user_merchant_any.astype('float')\n",
    "user_merchant2['user_merchant_common_buy_rate'] = user_merchant2.user_merchant_buy_common.astype('float') / user_merchant2.user_merchant_buy_total.astype('float')\n",
    "user_merchant2.to_csv('C:/Users/yanta/Desktop/MSBD 5012 ML/project/user_merchant2.csv',index=None)\n",
    "\n",
    "#for dataset2\n",
    "all_user_merchant = feature1[['user_id','merchant_id']].copy()\n",
    "all_user_merchant.drop_duplicates(inplace=True)\n",
    "\n",
    "t = feature1[['user_id','merchant_id','date']]\n",
    "t = t[t.date!='null'][['user_id','merchant_id']]\n",
    "t['user_merchant_buy_total'] = 1\n",
    "t = t.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t.drop_duplicates(inplace=True)\n",
    "\n",
    "t1 = feature1[['user_id','merchant_id','coupon_id']]\n",
    "t1 = t1[t1.coupon_id!='null'][['user_id','merchant_id']]\n",
    "t1['user_merchant_received'] = 1\n",
    "t1 = t1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t1.drop_duplicates(inplace=True)\n",
    "\n",
    "t2 = feature1[['user_id','merchant_id','date','date_received']]\n",
    "t2 = t2[(t2.date!='null')&(t2.date_received!='null')][['user_id','merchant_id']]\n",
    "t2['user_merchant_buy_use_coupon'] = 1\n",
    "t2 = t2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t2.drop_duplicates(inplace=True)\n",
    "\n",
    "t3 = feature1[['user_id','merchant_id']].copy()\n",
    "t3['user_merchant_any'] = 1\n",
    "t3 = t3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t3.drop_duplicates(inplace=True)\n",
    "\n",
    "t4 = feature1[['user_id','merchant_id','date','coupon_id']]\n",
    "t4 = t4[(t4.date!='null')&(t4.coupon_id=='null')][['user_id','merchant_id']]\n",
    "t4['user_merchant_buy_common'] = 1\n",
    "t4 = t4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "t4.drop_duplicates(inplace=True)\n",
    "\n",
    "user_merchant1 = pd.merge(all_user_merchant,t,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t1,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t2,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t3,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1 = pd.merge(user_merchant1,t4,on=['user_id','merchant_id'],how='left')\n",
    "user_merchant1.user_merchant_buy_use_coupon = user_merchant1.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "user_merchant1.user_merchant_buy_common = user_merchant1.user_merchant_buy_common.replace(np.nan,0)\n",
    "user_merchant1['user_merchant_coupon_transfer_rate'] = user_merchant1.user_merchant_buy_use_coupon.astype('float') / user_merchant1.user_merchant_received.astype('float')\n",
    "user_merchant1['user_merchant_coupon_buy_rate'] = user_merchant1.user_merchant_buy_use_coupon.astype('float') / user_merchant1.user_merchant_buy_total.astype('float')\n",
    "user_merchant1['user_merchant_rate'] = user_merchant1.user_merchant_buy_total.astype('float') / user_merchant1.user_merchant_any.astype('float')\n",
    "user_merchant1['user_merchant_common_buy_rate'] = user_merchant1.user_merchant_buy_common.astype('float') / user_merchant1.user_merchant_buy_total.astype('float')\n",
    "user_merchant1.to_csv('C:/Users/yanta/Desktop/MSBD 5012 ML/project/user_merchant1.csv',index=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################  generate training and testing set ################\n",
    "def get_label(s):\n",
    "    s = s.split(':')\n",
    "    if s[0]=='null':\n",
    "        return 0\n",
    "    elif (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8]))-date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days<=15:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "coupon3 = pd.read_csv('data/coupon3_feature.csv')\n",
    "merchant3 = pd.read_csv('data/merchant3_feature.csv')\n",
    "user3 = pd.read_csv('data/user3_feature.csv')\n",
    "user_merchant3 = pd.read_csv('data/user_merchant3.csv')\n",
    "other_feature3 = pd.read_csv('data/other_feature3.csv')\n",
    "dataset3 = pd.merge(coupon3,merchant3,on='merchant_id',how='left')\n",
    "dataset3 = pd.merge(dataset3,user3,on='user_id',how='left')\n",
    "dataset3 = pd.merge(dataset3,user_merchant3,on=['user_id','merchant_id'],how='left')\n",
    "dataset3 = pd.merge(dataset3,other_feature3,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset3.drop_duplicates(inplace=True)\n",
    "print(dataset3.shape)\n",
    "\n",
    "dataset3.user_merchant_buy_total = dataset3.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset3.user_merchant_any = dataset3.user_merchant_any.replace(np.nan,0)\n",
    "dataset3.user_merchant_received = dataset3.user_merchant_received.replace(np.nan,0)\n",
    "dataset3['is_weekend'] = dataset3.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset3.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset3 = pd.concat([dataset3,weekday_dummies],axis=1)\n",
    "dataset3.drop(['merchant_id','day_of_week','coupon_count'],axis=1,inplace=True)\n",
    "dataset3 = dataset3.replace('null',np.nan)\n",
    "dataset3.to_csv('data/dataset3.csv',index=None)\n",
    "\n",
    "\n",
    "coupon2 = pd.read_csv('data/coupon2_feature.csv')\n",
    "merchant2 = pd.read_csv('data/merchant2_feature.csv')\n",
    "user2 = pd.read_csv('data/user2_feature.csv')\n",
    "user_merchant2 = pd.read_csv('data/user_merchant2.csv')\n",
    "other_feature2 = pd.read_csv('data/other_feature2.csv')\n",
    "dataset2 = pd.merge(coupon2,merchant2,on='merchant_id',how='left')\n",
    "dataset2 = pd.merge(dataset2,user2,on='user_id',how='left')\n",
    "dataset2 = pd.merge(dataset2,user_merchant2,on=['user_id','merchant_id'],how='left')\n",
    "dataset2 = pd.merge(dataset2,other_feature2,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset2.drop_duplicates(inplace=True)\n",
    "print(dataset2.shape)\n",
    "\n",
    "dataset2.user_merchant_buy_total = dataset2.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset2.user_merchant_any = dataset2.user_merchant_any.replace(np.nan,0)\n",
    "dataset2.user_merchant_received = dataset2.user_merchant_received.replace(np.nan,0)\n",
    "dataset2['is_weekend'] = dataset2.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset2.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset2 = pd.concat([dataset2,weekday_dummies],axis=1)\n",
    "dataset2['label'] = dataset2.date.astype('str') + ':' +  dataset2.date_received.astype('str')\n",
    "dataset2.label = dataset2.label.apply(get_label)\n",
    "dataset2.drop(['merchant_id','day_of_week','date','date_received','coupon_id','coupon_count'],axis=1,inplace=True)\n",
    "dataset2 = dataset2.replace('null',np.nan)\n",
    "dataset2.to_csv('data/dataset2.csv',index=None)\n",
    "\n",
    "\n",
    "coupon1 = pd.read_csv('data/coupon1_feature.csv')\n",
    "merchant1 = pd.read_csv('data/merchant1_feature.csv')\n",
    "user1 = pd.read_csv('data/user1_feature.csv')\n",
    "user_merchant1 = pd.read_csv('data/user_merchant1.csv')\n",
    "other_feature1 = pd.read_csv('data/other_feature1.csv')\n",
    "dataset1 = pd.merge(coupon1,merchant1,on='merchant_id',how='left')\n",
    "dataset1 = pd.merge(dataset1,user1,on='user_id',how='left')\n",
    "dataset1 = pd.merge(dataset1,user_merchant1,on=['user_id','merchant_id'],how='left')\n",
    "dataset1 = pd.merge(dataset1,other_feature1,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset1.drop_duplicates(inplace=True)\n",
    "print(dataset1.shape)\n",
    "\n",
    "dataset1.user_merchant_buy_total = dataset1.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset1.user_merchant_any = dataset1.user_merchant_any.replace(np.nan,0)\n",
    "dataset1.user_merchant_received = dataset1.user_merchant_received.replace(np.nan,0)\n",
    "dataset1['is_weekend'] = dataset1.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "weekday_dummies = pd.get_dummies(dataset1.day_of_week)\n",
    "weekday_dummies.columns = ['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset1 = pd.concat([dataset1,weekday_dummies],axis=1)\n",
    "dataset1['label'] = dataset1.date.astype('str') + ':' +  dataset1.date_received.astype('str')\n",
    "dataset1.label = dataset1.label.apply(get_label)\n",
    "dataset1.drop(['merchant_id','day_of_week','date','date_received','coupon_id','coupon_count'],axis=1,inplace=True)\n",
    "dataset1 = dataset1.replace('null',np.nan)\n",
    "dataset1.to_csv('data/dataset1.csv',index=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
